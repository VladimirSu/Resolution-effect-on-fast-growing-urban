{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b899ac4-854a-4857-9b95-44757fd430d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 10:53:11.198337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# Implement Learning rate decay\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,LearningRateScheduler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D\n",
    "from tensorflow.keras.layers import ConvLSTM2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from math import sqrt  \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import requests\n",
    "import os\n",
    "import h5py\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cccdaf2-2519-42dc-9a14-8e7fb75041ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_dataset_from_raw():\n",
    "# 遍历当前子目录内所有图像，逐个处理\n",
    "    dataset = []\n",
    "    idxx = 0\n",
    "    idx = []\n",
    "    # 取13-17年16——10区域图像\n",
    "    for i in tqdm(range(1, 20)):\n",
    "        for j in range(1, 22):\n",
    "            data = []\n",
    "            for year in range(2016, 2018):\n",
    "                file = \"target/\" + str(year) +\"_\"+ str(i) +\"_\"+ str(j) + \".jpg\"\n",
    "                # 读入hdf5格式的图像数据，并转换为numpy数组        \n",
    "                img = Image.open(file)\n",
    "                original_image = np.array(img)\n",
    "                original_image = original_image.reshape(1,original_image.shape[0], original_image.shape[1], original_image.shape[2])\n",
    "                #归一化\n",
    "                original_image = original_image / 255.0\n",
    "                \n",
    "                #将所有年份的数据放入data\n",
    "                if(year == 2016):\n",
    "                    data = original_image\n",
    "                else:\n",
    "                    data = np.concatenate((data,original_image),axis=0)\n",
    "            \n",
    "            #将数据reshape为（sample， year， height， width， depth）\n",
    "            data = data.reshape(1, data.shape[0], data.shape[1], data.shape[2], data.shape[3])\n",
    "            index = np.array([i, j])\n",
    "            index = index.reshape(1, 2)\n",
    "            if(idxx == 0):\n",
    "                dataset = data\n",
    "                idx = index\n",
    "            else:\n",
    "                dataset = np.concatenate((dataset,data),axis=0)\n",
    "                idx = np.concatenate((idx, index),axis=0)\n",
    "            idxx += 1\n",
    "    # 将当前批次内所有图像的处理结果存入`dataset`数组中\n",
    "    return dataset, idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a81e7944-72d8-47f0-a81b-30071368e6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:41<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "val_dataset, index = create_dataset_from_raw()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fab2a0e-6bc3-482d-8ca0-e3ca32d62b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 2, 100, 100, 3)\n",
      "(399, 2)\n"
     ]
    }
   ],
   "source": [
    "print(val_dataset.shape)\n",
    "print(index.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c14a777-db97-409d-a93e-ff04addfe75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"100_timesteps2.h5\", custom_objects={'LeakyReLU':tf.keras.layers.LeakyReLU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8d61944-4bb1-4d17-9cae-0703b13e04f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 22:17:48.176583: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
      "2023-04-11 22:17:50.658217: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n"
     ]
    }
   ],
   "source": [
    "new_prediction = model.predict(val_dataset) \n",
    "\n",
    "# new_prediction = np.squeeze(new_prediction, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43ed781f-5b65-4ae8-afd0-af4d9e4ec720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 2, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "print(new_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "108e54ff-21d9-4c6a-9800-5724a1f00f85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399/399 [05:59<00:00,  1.11it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHMAAABzCAYAAACrQz3mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAABSUlEQVR4nO3XMQrDQAwAQZ+T/z/ZygviNCY2y0yrRrCc4NbMbDTsdy/AdcQMETNEzBAxQ8QMeZ8N99c+c/i6PMbatjlmfRufvkwhH+ZHDmc2RMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMwQMUPEDBEzRMyQ05hrrX/twQXWzNy9AxdxZkPEDBEzRMwQMUPEDPkAVusR30AOUwkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 100.8x100.8 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# fig, axes = plt.subplots(2, 5, figsize=(20, 4))\n",
    "\n",
    "# Plot the original frames.\n",
    "# year = 2013\n",
    "# for idx, ax in enumerate(axes[0]):\n",
    "#     ax.imshow(np.squeeze(val_dataset[idx]), cmap=\"viridis\")\n",
    "#     ax.set_title(f\"Actual {year}\")\n",
    "#     ax.axis(\"off\")\n",
    "#     year += 1\n",
    "\n",
    "# Plot the predicted frames.\n",
    "plt.figure(figsize=(1.4,1.4))\n",
    "for idx in tqdm(range(0, new_prediction.shape[0])):\n",
    "    plt.imshow((new_prediction[idx,0,:,:,:]), cmap=\"viridis\")\n",
    "    plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    plt.margins(0, 0)\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"result_100_timesteps2/2018_\"+str(index[idx, 0])+\"_\"+str(index[idx, 1])+\".png\")\n",
    "    \n",
    "# Display the figure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249eb75d-a715-4701-9b4c-1b2cf6fe026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_compose():\n",
    "    IMAGE_ROW = 20\n",
    "    IMAGE_COLUMN = 22\n",
    "    IMAGE_SIZE = 100\n",
    "    to_image = Image.new('RGB',(2155,1902))  # 创建一个新图\n",
    "    # 循环遍历，把每张图片按顺序粘贴到对应位置上\n",
    "    for i in range(1, IMAGE_ROW):\n",
    "        for j in range(1, IMAGE_COLUMN):\n",
    "            from_image = Image.open('result_100_timesteps4/2018'+\"_\"+ str(i) +\"_\"+ str(j) + \".png\")\n",
    "            to_image.paste(from_image, ((j-1) * IMAGE_SIZE, (i-1) * IMAGE_SIZE))\n",
    "                           \n",
    "    to_image.save('100_timesteps2_big.png')  # 保存新图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30ef057e-e2cc-433e-9d6d-8e7a4533f693",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_true(Folder, format):\n",
    "# 遍历当前子目录内所有图像，逐个处理\n",
    "    dataset = []\n",
    "    idx = 0\n",
    "    # 取13-17年16——10区域图像\n",
    "    for i in tqdm(range(1, 20)):\n",
    "        data = []\n",
    "        for j in range(1, 22):\n",
    "            file = Folder + \"/2018_\"+ str(i) +\"_\"+ str(j) + format\n",
    "            # 读入hdf5格式的图像数据，并转换为numpy数组        \n",
    "            img = Image.open(file)\n",
    "            original_image = np.array(img)\n",
    "            original_image = original_image.reshape(1,original_image.shape[0], original_image.shape[1], original_image.shape[2])\n",
    "\n",
    "            #将所有年份的数据放入data\n",
    "            if(j == 1):\n",
    "                data = original_image\n",
    "            else:\n",
    "                data = np.concatenate((data,original_image),axis=0)\n",
    "            \n",
    "        if(idx == 0):\n",
    "            dataset = data\n",
    "        else:\n",
    "            dataset = np.concatenate((dataset,data),axis=0)\n",
    "        idx += 1\n",
    "    # 将当前批次内所有图像的处理结果存入`dataset`数组中\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74f13b90-1d30-4d6e-a1be-20abb4cdd6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_compose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f439d24-cb08-4cc8-b078-6e22f709eebe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
